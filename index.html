<!doctype html>
<html lang="en">
  <head>
    <title>Steven M. Goodman</title>
    <meta charset="utf-8" />
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=Inter+Tight:ital,wght@0,100;0,200;0,300;0,400;0,600;1,700&family=Inter:wght@300&display=swap"
      rel="stylesheet"
    />
    <meta name="viewport" content="width=device-width" />
    
		<link href="./app/immutable/assets/0.19ad40f6.css" rel="stylesheet">
		<link href="./app/immutable/assets/2.c51dff12.css" rel="stylesheet">
		<link rel="modulepreload" href="./app/immutable/entry/start.9583a192.js">
		<link rel="modulepreload" href="./app/immutable/chunks/scheduler.ba4dd0f0.js">
		<link rel="modulepreload" href="./app/immutable/chunks/singletons.800d778c.js">
		<link rel="modulepreload" href="./app/immutable/entry/app.6d89cf4e.js">
		<link rel="modulepreload" href="./app/immutable/chunks/index.efe6f06d.js">
		<link rel="modulepreload" href="./app/immutable/nodes/0.997cfc80.js">
		<link rel="modulepreload" href="./app/immutable/nodes/2.454eaa3e.js">
  </head>
  <body data-sveltekit-preload-data="hover">
    <div style="display: contents">  <div class="_main-container"><nav class="sidenav" data-svelte-h="svelte-rf5diz"><div class="headshot"><img src="images/SG_headshot.jpeg" alt="Steven Goodman, a white man with short brown hair and a slight beard is visible from the shoulders up standing in front of a solid white background and wearing a dark shirt. He is looking directly at the camera and smiling. The photo is in black and white." class="me_picture"></div> <a href="#about_header">About</a> <a href="#publications_header">Publications</a> <a href="#talks_header">Talks/Videos</a> <a href="Steven-Goodman_CV.pdf">CV</a></nav> <header role="banner" data-svelte-h="svelte-1gpezp6"><h1 class="main_title">Steven M. Goodman</h1></header> <a href="#mobile_nav" id="nav_button"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32" fill="currentColor" preserveAspectRatio="xMidYMid meet" width="32" height="32" aria-hidden><path d="M4 6H28V8H4zM4 24H28V26H4zM4 12H28V14H4zM4 18H28V20H4z"></path></svg></a> <main role="main"><div class="center" data-svelte-h="svelte-u9o7xk"><img src="images/SG_headshot.jpeg" alt="Steven Goodman, a white man with short brown hair and a slight beard is visible from the shoulders up standing in front of a solid white background and wearing a dark shirt. He is looking directly at the camera and smiling. The photo is in black and white." class="mobile_picture svelte-10k7k3g"></div> <h2 id="about_header" data-svelte-h="svelte-1e4d2as">About Me</h2> <div><p data-svelte-h="svelte-os32h5">I am a Ph.D. candidate in Human Centered Design &amp; Engineering at the University of Washington. I
    am a human-computer interaction researcher focusing on accessibility technologies, and my
    graduate work looks at sound awareness tools for people who are Deaf, deaf, or hard of hearing.
    My dissertation aims to create a framework for supporting this population in personalizing sound
    recognition models via accessible interfaces for audio sampling, human-in-the-loop training, and
    model assessment. I am broadly interested in issues at the intersection of AI and accessibility,
    including AI fairness for vulnerable populations; end-user agency and trust; and privacy and
    data protection.</p> <p data-svelte-h="svelte-rbzx2n">I am in my final year of study and am currently on the job market... I completed my
    undergraduate degree at the University of Minnesota... I have also worked at Google and NASA.</p> <p data-svelte-h="svelte-18qinys">I research accessibility technologies, and my graduate work focuses on sound awareness tools for
    people who are Deaf, deaf, or hard of hearing. My dissertation aims to create a framework for
    supporting this population in personalizing sound recognition tools via accessible interfaces
    for audio sampling, human-in-the-loop machine learning, and model assessment.</p> <p data-svelte-h="svelte-h21q14">I am broadly interested in issues at the intersection of AI and accessibility, including AI
    fairness for vulnerable populations; end-user agency and trust; and privacy and data protection.
    I was a recipient of the NSF Graduate Research Fellowship. I have experience working in a
    variety of research labs... I have design experience and sensibility (?)... I have building
    skills...</p> <p data-svelte-h="svelte-vk0mt4">This page provides highlights of my work and demonstrates my skillset as a Human-Computer
    Interaction researcher. Please refer to my Curriculum Vitae for a complete overview of my
    experience and history.</p> <div><span class="icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32" fill="currentColor" preserveAspectRatio="xMidYMid meet" width="32" height="32" aria-hidden><path d="M28,6H4A2,2,0,0,0,2,8V24a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V8A2,2,0,0,0,28,6ZM25.8,8,16,14.78,6.2,8ZM4,24V8.91l11.43,7.91a1,1,0,0,0,1.14,0L28,8.91V24Z"></path></svg></span> smgoodmn [at] uw [dot] edu</div> <div><span class="icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32" fill="currentColor" preserveAspectRatio="xMidYMid meet" width="32" height="32" aria-hidden><path d="M28,10H22V6a2,2,0,0,0-2-2H12a2,2,0,0,0-2,2v4H4a2,2,0,0,0-2,2V26a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V12A2,2,0,0,0,28,10ZM12,6h8v4H12ZM4,26V12H28V26Z"></path></svg></span> <a href="" data-svelte-h="svelte-1gxp8ci">LinkedIn</a></div> <div><span class="icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32" fill="currentColor" preserveAspectRatio="xMidYMid meet" width="32" height="32" aria-hidden><path d="M26 30H24V27a5.0059 5.0059 0 00-5-5H13a5.0059 5.0059 0 00-5 5v3H6V27a7.0082 7.0082 0 017-7h6a7.0082 7.0082 0 017 7zM5 6A1 1 0 004 7v9H6V7A1 1 0 005 6z"></path><path d="M4,2V4H9v7a7,7,0,0,0,14,0V4h5V2Zm7,2H21V7H11Zm5,12a5,5,0,0,1-5-5V9H21v2A5,5,0,0,1,16,16Z"></path></svg></span> <a href="" data-svelte-h="svelte-yzdeos">Scholar</a></div> <div><span class="icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32" fill="currentColor" preserveAspectRatio="xMidYMid meet" width="32" height="32" aria-hidden><path d="M30 18L30 16 24 16 24 26 26 26 26 22 29 22 29 20 26 20 26 18 30 18zM19 26H15V16h4a3.0033 3.0033 0 013 3v4A3.0033 3.0033 0 0119 26zm-2-2h2a1.0011 1.0011 0 001-1V19a1.0011 1.0011 0 00-1-1H17zM11 16H6V26H8V23h3a2.0027 2.0027 0 002-2V18A2.0023 2.0023 0 0011 16zM8 21V18h3l.001 3z"></path><path d="M22,14V10a.9092.9092,0,0,0-.3-.7l-7-7A.9087.9087,0,0,0,14,2H4A2.0059,2.0059,0,0,0,2,4V28a2,2,0,0,0,2,2H20V28H4V4h8v6a2.0059,2.0059,0,0,0,2,2h6v2Zm-8-4V4.4L19.6,10Z"></path></svg></span> <a href="Steven-Goodman_CV.pdf" data-svelte-h="svelte-1br5pfj">Curriculum Vitae</a></div> <p><i>Last updated: October 2023</i></p> <p data-svelte-h="svelte-grvaag">I am an Assistant Professor in <a href="https://cse.engin.umich.edu/">Computer Science and Engineering</a>
    at the <a href="https://umich.edu/">University of Michigan</a>, also affiliated with the
    <a href="https://www.si.umich.edu/">School of Information</a>
    and <a href="https://disabilityhealth.medicine.umich.edu/">Michigan Medicine</a>. I am also the
    <a href="https://sigchi.org/">ACM SIGCHI</a>
    VP for Accessibility, overseeing the executive committee policy and accessibility of over 27 SIGCHI
    sponsored conferences. I received my PhD from
    <a href="https://www.washington.edu/">University of Washington</a>, masters from
    <a href="https://www.media.mit.edu/">MIT Media Lab</a>, and I have worked at Microsoft Research,
    Google, and Apple.</p> <p data-svelte-h="svelte-t8k2id">My research lies in human-computer interaction (HCI). At Michigan, I lead the <a href="https://accessibility.eecs.umich.edu/">Accessibility Lab</a>, where I am joined by a passionate group of students and collaborators with one common aim: to
    build and study interactive systems that solve pressing accessibility challenges. Our research
    work has been released publicly, has directly impacted products at Microsoft, Google, and Apple,
    and has been honored with several best paper and honorable mention awards. Please see our
    <a href="https://accessibility.eecs.umich.edu/">lab&#39;s website</a> for our current focus areas and
    projects.</p> <p data-svelte-h="svelte-ayyjb4">I also have over 10 years of experience serving in departmental and conference committees on DEI
    and accessibility. I was instrumental in pioneering new efforts at leading computer science
    conferences to improve accessibility of poster sessions for blind attendees and real-time
    captioning for deaf and hard-of-hearing attendees. I am also a member of HCI4SoundAsia, with
    aims to broaden participation of South East Asian researchers in human-computer interaction
    conferences, and I am currently serving as the inaugural <a href="https://sigchi.org/">ACM SIGCHI</a> VP for accessibility.</p> <p data-svelte-h="svelte-1b9nt7v">I teach Accessibility Studio for undergraduate students (in Winter) and Advanced Accessibility
    for graduate students (in Fall). I also frequently participate in educational outreach, in the
    form of two-week DIY workshops which I help co-organize with local instructors. Thus far, I have
    organized seven workshops in four different countries. These events have been hugely successful
    in inculcating an entrepreneurial mindset in underserved students. To disclose a specific known
    outcome, three teams of undergraduate students have continued their projects from the workshops
    and turned them into multinational companies with global impact!</p></div> <h2 id="publications_header" data-svelte-h="svelte-ai5cix">Selected Publications</h2> <ul id="main_pubs_list"><li> <div class="pub_title">“Easier or Harder, Depending on Who the Hearing Person Is”: Codesigning Videoconferencing Tools for Small Groups with Mixed Hearing Status</div> <div class="pub_author_list">Emma McDonnell, Soo Hyun Moon, Lucy Jiang, <strong>Steven Goodman, </strong>Raja Kushalnagar, Jon E. Froehlich, Leah Findlater</div> <div class="pub_venue_name">ACM CHI 2023</div>  <div class="pub_links_container">(
        <a href="papers/McDonnell_CHI2023_Easier-or-Harder.pdf">Paper</a> | <a href="https://youtu.be/pOpsIms3DTA">Talk</a> | <a href="https://doi.org/10.1145/3544548.3580809">doi</a>
        )</div> </li><li><img src="images/2022_LaMPost_square.png" alt="Part of Figure 5 in the paper, showing the user interface of an email composition tool and the 'Rewrite My Selection' feature described in this work. Copied here for decorative purposes."> <div class="pub_title">LaMPost: Design and Evaluation of an AI-assisted Email Writing Prototype for Adults with Dyslexia</div> <div class="pub_author_list"><strong>Steven Goodman, </strong>Andy Coenen, Aaron Donsbach, Tiffanie N. Horne, Michal Lahav, Robert MacDonald, Rain Breaw Michaels, Ajit Narayanan, Mahima Pushkarna, Rachel Sweeney, Meredith Ringel Morris</div> <div class="pub_venue_name">ACM ASSETS 2022</div> <div class="pub_award">Best Paper Nominee</div> <div class="pub_links_container">(
        <a href="papers/Goodman_ASSETS2022_LaMPost.pdf">Paper</a> | <a href="https://youtu.be/1JYUCcRcRg8">Talk</a> | <a href="https://doi.org/10.1145/3517428.3544819">doi</a>
        )</div> </li><li> <div class="pub_title">ProtoSound: A Personalized and Scalable Sound Recognition System for Deaf and Hard of Hearing Users</div> <div class="pub_author_list">Dhruv Jain, Khoa Nguyen, <strong>Steven Goodman, </strong>Rachel Grossman-Kahn, Hung Ngo, Aditya Kusupati, Ruofei Du, Alex Olwal, Leah Findlater, Jon Froehlich</div> <div class="pub_venue_name">ACM CHI 2022</div>  <div class="pub_links_container">(
        <a href="papers/Jain_CHI2022_Protosound.pdf">Paper</a> | <a href="https://www.youtube.com/watch?v=bDE95hKiLqw">Video</a> | <a href="https://github.com/makeabilitylab/ProtoSound">Code</a> | <a href="https://doi.org/10.1145/3491102.3502020">doi</a>
        )</div> </li><li><img src="images/2021_TMSR_square.jpg" alt="Image from Figure 2 of the paper, showing a participant recording a kettle boiling sound on a smartphone recording app. Copied here for decorative purposes."> <div class="pub_title">Toward User-Driven Sound Recognizer Personalization with People Who Are d/Deaf or Hard of Hearing</div> <div class="pub_author_list"><strong>Steven Goodman, </strong>Ping Liu, Dhruv Jain, Emma J. McDonnell, Jon Froehlich, Leah Findlater</div> <div class="pub_venue_name">ACM IMWUT 2021</div>  <div class="pub_links_container">(
        <a href="papers/Goodman_IMWUT2021_TowardUserDriven.pdf">Paper</a> | <a href="https://www.youtube.com/watch?v=GWNzKHhOvGE">Talk</a> | <a href="https://doi.org/10.1145/3463501">doi</a>
        )</div> </li><li> <div class="pub_title">Social, Environmental, and Technical: Factors at Play in the Current Use and Future Design of Small-Group Captioning</div> <div class="pub_author_list">Emma McDonnell, Ping Liu, <strong>Steven Goodman, </strong>Raja Kushalnagar, Jon Froehlich, Leah Findlater</div> <div class="pub_venue_name">PACMHCI CSCW 2021</div> <div class="pub_award">Honorable Mention</div> <div class="pub_links_container">(
        <a href="papers/McDonnell_CSCWPACMHCI2021_SocialEnvironmentalTechnical.pdf">Paper</a> | <a href="https://youtu.be/1TC8sfPQxxQ">Talk</a> | <a href="https://doi.org/10.1145/3479578">doi</a>
        )</div> </li><li><img src="images/2020_Smartwatches_square.jpg" alt="A person sitting in a coffee shop looking at a smartwatch, which displays the direction of a sound occurring in their vicinity. Copied here for decorative purposes."> <div class="pub_title">Evaluating Smartwatch-based Sound Feedback for Deaf and Hard-of-hearing Users Across Contexts</div> <div class="pub_author_list"><strong>Steven Goodman, </strong>Susanne Kirchner, Rose Guttman, Dhruv Jain, Jon Froehlich, Leah Findlater</div> <div class="pub_venue_name">ACM CHI 2020</div>  <div class="pub_links_container">(
        <a href="papers/Goodman_CHI2020_EvaluatingSmartwatchAcrossContexts.pdf">Paper</a> | <a href="https://doi.org/10.1145/3313831.3376406">doi</a>
        )</div> </li><li> <div class="pub_title">SoundWatch: Exploring Smartwatch-based Deep Learning Approaches to Support Sound Awareness for Deaf and Hard of Hearing Users</div> <div class="pub_author_list">Dhruv Jain, Hung Ngo, Pratyush Patel, <strong>Steven Goodman, </strong>Leah Findlater, Jon Froehlich</div> <div class="pub_venue_name">ACM ASSETS 2020</div> <div class="pub_award">Best Artifact Award</div> <div class="pub_links_container">(
        <a href="papers/Jain_ASSETS2020_Soundwatch.pdf">Paper</a> | <a href="https://doi.org/10.1145/3373625.3416991">doi</a>
        )</div> </li><li> <div class="pub_title">HoloSound: Combining Speech and Sound Identification for Deaf or Hard of Hearing Users on a Head-mounted Display</div> <div class="pub_author_list">Ru Guo, Robin Yiru Yang, Johnson Kuang, Xue Bin, Dhruv Jain, <strong>Steven Goodman, </strong>Leah Findlater, Jon Froehlich</div> <div class="pub_venue_name">ACM ASSETS 2020 Poster</div>  <div class="pub_links_container">(
        <a href="papers/Guo_POSTERASSETS2020_Holosound.pdf">Paper</a> | <a href="https://www.youtube.com/watch?v=-F9yL-XM02o">Video</a> | <a href="https://doi.org/10.1145/3373625.3418031">doi</a>
        )</div> </li><li> <div class="pub_title">Field Study of a Tactile Sound Awareness Device for Deaf Users</div> <div class="pub_author_list">Dhruv Jain, Brendon Chiu, <strong>Steven Goodman, </strong>Chris Schmandt, Leah Findlater, Jon Froehlich</div> <div class="pub_venue_name">ACM ISWC 2020</div>  <div class="pub_links_container">(
        <a href="papers/Jain_ISWC2020_FieldStudyOfATactile.pdf">Paper</a> | <a href="https://doi.org/10.1145/3410531.3414291">doi</a>
        )</div> </li><li> <div class="pub_title">HomeSound: An Iterative Field Deployment of an In-Home Sound Awareness System for Deaf or Hard of Hearing Users</div> <div class="pub_author_list">Dhruv Jain, Kelly Mack, Akli Amrous, <strong>Steven Goodman, </strong>Matt Wright, Leah Findlater, Jon Froehlich</div> <div class="pub_venue_name">ACM CHI 2020</div>  <div class="pub_links_container">(
        <a href="papers/Jain_CHI2020_Homesound.pdf">Paper</a> | <a href="https://doi.org/10.1145/3313831.3376758">doi</a>
        )</div> </li><li> <div class="pub_title">Social Tensions with Head-Mounted Displays for Accessibility</div> <div class="pub_author_list"><strong>Steven Goodman, </strong>Dhruv Jain, Jon Froehlich, Brock Craft, Leah Findlater</div> <div class="pub_venue_name">ACM CHI 2019 Extended Abstracts</div>  <div class="pub_links_container">(
        <a href="papers/Goodman_CHI2019EA_SocialHMD.pdf">Paper</a>
        )</div> </li> </ul> <h2 id="talks_header" data-svelte-h="svelte-cuc4qr">Talks/Videos</h2> <ul id="talks_list"><li><div><a href="slides/UW-2023_Dissertation-Proposal_slides.pdf"><img src="images/UW2023_Proposal_slide-preview.png" alt="First slide of the talk with white text on a blue background. The title reads: Human-Centered Sound Recognition Tools for Deaf and Hard of Hearing People."> </a></div> <h3>Human-Centered Sound Recognition Tools</h3> <div>April 18, 2023 | Public proposal at the University of Washington  | <a href="slides/UW-2023_Dissertation-Proposal_slides.pdf">Slides</a></div> </li><li><div><div class="aspect-w-16 aspect-h-9"><iframe title="Youtube video for Human-Centered Sound Recognition Tools" src="https://www.youtube.com/embed/1JYUCcRcRg8?rel=0&amp;cc_load_policy=1&amp;iv_load_policy=3&amp;color=white" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> </div></div> <h3>Human-Centered Sound Recognition Tools</h3> <div>October 25, 2022 | ASSETS 2022 in Athens, Greece  | <a href="slides/ASSETS-2022_LaMPost_slides.pdf">Slides</a></div> </li><li><div><div class="aspect-w-16 aspect-h-9"><iframe title="Youtube video for Toward User-Driven Sound Recognizer Personalization" src="https://www.youtube.com/embed/v5qvlZD6aKE?rel=0&amp;cc_load_policy=1&amp;iv_load_policy=3&amp;color=white" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> </div></div> <h3>Toward User-Driven Sound Recognizer Personalization</h3> <div>September 22, 2021 | Virtual event for paper at UbiComp 2021  | <a href="slides/IMWUT-2021_TMSR_slides.pdf">Slides</a></div> </li><li><div><a href="slides/CHI-2020_Smartwatches_slides.pdf"><img src="images/CHI2020_Smartwatches_slide-preview.png" alt="First slide of the talk with an image of an individual standing at a crosswalk and looking at a smartwatch on their wrist. In the background, a car drives past while a bicyclist approaches. The title reads: Evaluating Smartwatch-based Sound Feedback for Deaf and Hard-of-Hearing Users Across Contexts."> </a></div> <h3>Smartwatch Sound Feedback Across Contexts</h3> <div>November 22, 2019 | University of Washington (in anticipation of CHI 2020 paper)  | <a href="slides/CHI-2020_Smartwatches_slides.pdf">Slides</a></div> </li><li><div><a href="slides/CHI-SHMD-2019_SocialHMD_slides.pdf"><img src="images/CHI2019EA_SocialHMD_slide-preview.png" alt="First slide of the talk with an image of a two individuals talking. One is wearing a head-mounted display that is projecting simulated captions beneath the other person. The title reads: Social Tensions with HMDs for Accessibility."> </a></div> <h3>Social Tensions with HMDs for Accessibility</h3> <div>May 5, 2019 | Social HMDs workshop at CHI 2019 in Glasgow, Scotland  | <a href="slides/CHI-SHMD-2019_SocialHMD_slides.pdf">Slides</a></div> </li></ul> <article class="group relative flex flex-col items-start" data-svelte-h="svelte-1apmckd"><h3 class="text-base font-semibold tracking-tight text-zinc-800 dark:text-zinc-100"><div class="absolute -inset-x-4 -inset-y-6 z-0 scale-95 bg-zinc-50 opacity-0 transition group-hover:scale-100 group-hover:opacity-100 dark:bg-zinc-800/50 sm:-inset-x-6 sm:rounded-2xl"></div> <a href="#"><span class="absolute -inset-x-4 -inset-y-6 z-20 sm:-inset-x-6 sm:rounded-2xl"></span><span class="relative z-10">In space, no one can watch you stream — until now</span></a></h3> <p class="relative z-10 order-first mb-3 flex items-center text-sm text-zinc-400 dark:text-zinc-500 pl-3.5"><span class="absolute inset-y-0 left-0 flex items-center" aria-hidden="true"><span class="h-4 w-0.5 rounded-full bg-zinc-200 dark:bg-zinc-500"></span></span>SysConf 2021</p> <p class="relative z-10 mt-2 text-sm text-zinc-600 dark:text-zinc-400">A technical deep-dive into HelioStream, the real-time streaming library I wrote for transmitting
    live video back to Earth.</p> <div aria-hidden="true" class="relative z-10 mt-4 flex items-center text-sm font-medium text-teal-500">Watch video<svg viewBox="0 0 16 16" fill="none" aria-hidden="true" class="ml-1 h-4 w-4 stroke-current"><path d="M6.75 5.75 9.25 8l-2.5 2.25" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></div></article> <ul id="videos_list"><li><h3>ProtoSound: Personalized, Scalable Sound Awareness</h3> <div>April 3, 2022</div> <div class="aspect-w-16 aspect-h-9"><iframe title="Youtube video for ProtoSound: Personalized, Scalable Sound Awareness" src="https://www.youtube.com/embed/bDE95hKiLqw?rel=0&amp;cc_load_policy=1&amp;iv_load_policy=3&amp;color=white" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div> <div>Produced video to demonstrate prototype and support co-authored work at CHI 2022.</div> </li><li><h3>HoloSound: AR Sound Awareness</h3> <div>July 31, 2020</div> <div class="aspect-w-16 aspect-h-9"><iframe title="Youtube video for HoloSound: AR Sound Awareness" src="https://www.youtube.com/embed/-F9yL-XM02o?rel=0&amp;cc_load_policy=1&amp;iv_load_policy=3&amp;color=white" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div> <div>Produced video to demonstrate prototype and support a co-authored poster at ASSETS 2020.</div> </li> </ul></main> <footer role="contentinfo" data-svelte-h="svelte-1yyq5ve"><div class="foot_div"><p>Connect with me on <a href="https://twitter.com/ej_mcdonnell" class="footer-link">Twitter</a>
        or <a href="https://www.linkedin.com/in/ejmcdonnell/" class="footer-link">Linked In</a></p></div></footer> <nav role="navigation" id="mobile_nav" data-svelte-h="svelte-1vhi57g"><ul><li><a href="#about_header">About</a></li> <li><a href="#publications_header">Publications</a></li> <li><a href="#talks_header">Talks/Videos</a></li> <li><a href="Steven-Goodman_CV.pdf">CV</a></li></ul></nav> </div> 
			
			<script>
				{
					__sveltekit_1ggtqrj = {
						base: new URL(".", location).pathname.slice(0, -1),
						env: {}
					};

					const element = document.currentScript.parentElement;

					const data = [null,null];

					Promise.all([
						import("./app/immutable/entry/start.9583a192.js"),
						import("./app/immutable/entry/app.6d89cf4e.js")
					]).then(([kit, app]) => {
						kit.start(app, element, {
							node_ids: [0, 2],
							data,
							form: null,
							error: null
						});
					});
				}
			</script>
		</div>
  </body>
</html>
