<!doctype html>
<html lang="en">
  <head>
    <title>Steven M. Goodman</title>
    <meta charset="utf-8" />
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=Inter+Tight:ital,wght@0,100;0,200;0,300;0,400;0,600;1,700&family=Inter:wght@300&display=swap"
      rel="stylesheet"
    />
    <meta name="viewport" content="width=device-width" />
    
		<link href="./app/immutable/assets/0.b8b957f5.css" rel="stylesheet">
		<link href="./app/immutable/assets/2.29965c9a.css" rel="stylesheet">
		<link rel="modulepreload" href="./app/immutable/entry/start.8c1e7e81.js">
		<link rel="modulepreload" href="./app/immutable/chunks/scheduler.ba4dd0f0.js">
		<link rel="modulepreload" href="./app/immutable/chunks/singletons.3f568260.js">
		<link rel="modulepreload" href="./app/immutable/entry/app.e51145c7.js">
		<link rel="modulepreload" href="./app/immutable/chunks/index.539872ee.js">
		<link rel="modulepreload" href="./app/immutable/nodes/0.b1c86604.js">
		<link rel="modulepreload" href="./app/immutable/nodes/2.0c5e4468.js">
  </head>
  <body data-sveltekit-preload-data="hover">
    <div style="display: contents">  <div class="_main-container"><header><nav class="bg-white fixed w-full z-20 top-0 left-0 border-b border-black"><ul class="navigation w-[90vw] max-w-5xl flex flex-wrap justify-between items-center relative mx-auto py-6"><a class="logo" href="#top" data-svelte-h="svelte-63tnej"><h1 class="font-bold text-2xl text-black">Steven M. Goodman</h1></a> <input type="checkbox" id="check"> <span class="menu flex [&>li]:px-4 [&>li>a]:text-center [&>li>a]:relative [&>li>a]:transition [&>li>a]:duration-200 [&>li>a]:ease-in-out [&>li>a]:font-medium svelte-18f0hit"><li class="svelte-18f0hit" data-svelte-h="svelte-1bl46fw"><a href="#about_header" class="svelte-18f0hit">About</a></li> <li class="svelte-18f0hit" data-svelte-h="svelte-1bw5nsu"><a href="#publications_header" class="svelte-18f0hit">Publications</a></li> <li class="svelte-18f0hit" data-svelte-h="svelte-s4ckv7"><a href="#talks_header" class="svelte-18f0hit">Talks/Videos</a></li> <li class="svelte-18f0hit" data-svelte-h="svelte-leiyyv"><a href="Steven-Goodman_CV.pdf" class="svelte-18f0hit">CV</a></li> <label for="check" class="close-menu"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32" fill="currentColor" preserveAspectRatio="xMidYMid meet" width="32" height="32" aria-hidden class="text-black"><path d="M17.4141 16L26 7.4141 24.5859 6 16 14.5859 7.4143 6 6 7.4141 14.5859 16 6 24.5859 7.4143 26 16 17.4141 24.5859 26 26 24.5859 17.4141 16z"></path></svg></label></span> <label for="check" class="open-menu"><div class="p-2"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32" fill="currentColor" preserveAspectRatio="xMidYMid meet" width="32" height="32" aria-hidden><path d="M4 6H28V8H4zM4 24H28V26H4zM4 12H28V14H4zM4 18H28V20H4z"></path></svg></div></label></ul></nav></header> <main class="mx-auto" id="top"><section class="svelte-18f0hit"><div class="max-w-xs px-2.5 lg:max-w-none" data-svelte-h="svelte-12zh2eu"><img src="images/SG_headshot.jpeg" loading="lazy" decoding="async" style="color: transparent;" alt="Steven Goodman, a white man with short brown hair and a slight beard is visible from the shoulders up standing in front of a solid white background and wearing a dark shirt. He is looking directly at the camera and smiling. The photo is in black and white." class="me_picture"></div> <h2 id="about_header" data-svelte-h="svelte-1e4d2as">About Me</h2> <div class="mt-6 space-y-7" data-svelte-h="svelte-qy63em"><p>Hello! I am a recent Ph.D. graduate from the department of Human Centered Design &amp; Engineering
    at the University of Washington, specializing in accessibility technologies and human-centered
    AI. My dissertation explored interactive machine learning tools for Deaf, deaf, or hard of
    hearing users to personalize their own sound recognition models, resulting in several
    publications at top HCI venues (CHI, ASSETS, IMWUT). Previously, at Google Research, I led the
    design and evaluation of an AI support tool for writers with dyslexia using large language
    models, and at NASA and the University of Minnesota, I supported the development of novel
    wearable systems.</p> <p>I am currently on the job market and seeking industry roles where I can leverage my user
    research expertise to build inclusive, impactful technologies. I bring expertise in user
    research (study design, interviewing, usability testing), rapid prototyping (web applications,
    wearables), and translating findings into actionable product guidance (experience in academic,
    industry, and government contexts). I am passionate about all issues at the intersection of AI
    and accessibility, including AI to assist users with disabilities; AI fairness; end-user agency
    and trust in AI systems; and privacy and data protection.</p> <p>Please refer to my Curriculum Vitae for a complete overview of my experience and history, or
    reach out if you’d like to learn more!</p></div> <div><div class="info_links svelte-18f0hit" id="email_link"><span class="icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32" fill="currentColor" preserveAspectRatio="xMidYMid meet" width="32" height="32" aria-hidden><path d="M28,6H4A2,2,0,0,0,2,8V24a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V8A2,2,0,0,0,28,6ZM25.8,8,16,14.78,6.2,8ZM4,24V8.91l11.43,7.91a1,1,0,0,0,1.14,0L28,8.91V24Z"></path></svg></span> smgoodmn [at] gmail [dot] com</div> <div class="info_links svelte-18f0hit"><span class="icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32" fill="currentColor" preserveAspectRatio="xMidYMid meet" width="32" height="32" aria-hidden><path d="M30 18L30 16 24 16 24 26 26 26 26 22 29 22 29 20 26 20 26 18 30 18zM19 26H15V16h4a3.0033 3.0033 0 013 3v4A3.0033 3.0033 0 0119 26zm-2-2h2a1.0011 1.0011 0 001-1V19a1.0011 1.0011 0 00-1-1H17zM11 16H6V26H8V23h3a2.0027 2.0027 0 002-2V18A2.0023 2.0023 0 0011 16zM8 21V18h3l.001 3z"></path><path d="M22,14V10a.9092.9092,0,0,0-.3-.7l-7-7A.9087.9087,0,0,0,14,2H4A2.0059,2.0059,0,0,0,2,4V28a2,2,0,0,0,2,2H20V28H4V4h8v6a2.0059,2.0059,0,0,0,2,2h6v2Zm-8-4V4.4L19.6,10Z"></path></svg></span> <a href="Steven-Goodman_CV.pdf" class="svelte-18f0hit" data-svelte-h="svelte-1br5pfj">Curriculum Vitae</a></div> <div class="info_links svelte-18f0hit"><span class="icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32" fill="currentColor" preserveAspectRatio="xMidYMid meet" width="32" height="32" aria-hidden><path d="M26 30H24V27a5.0059 5.0059 0 00-5-5H13a5.0059 5.0059 0 00-5 5v3H6V27a7.0082 7.0082 0 017-7h6a7.0082 7.0082 0 017 7zM5 6A1 1 0 004 7v9H6V7A1 1 0 005 6z"></path><path d="M4,2V4H9v7a7,7,0,0,0,14,0V4h5V2Zm7,2H21V7H11Zm5,12a5,5,0,0,1-5-5V9H21v2A5,5,0,0,1,16,16Z"></path></svg></span> <a href="https://scholar.google.com/citations?user=03HVZhQAAAAJ&amp;hl=en" class="svelte-18f0hit" data-svelte-h="svelte-yzdeos">Scholar</a></div> <div class="info_links svelte-18f0hit"><span class="icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32" fill="currentColor" preserveAspectRatio="xMidYMid meet" width="32" height="32" aria-hidden><path d="M28,10H22V6a2,2,0,0,0-2-2H12a2,2,0,0,0-2,2v4H4a2,2,0,0,0-2,2V26a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V12A2,2,0,0,0,28,10ZM12,6h8v4H12ZM4,26V12H28V26Z"></path></svg></span> <a href="https://www.linkedin.com/in/steven-m-goodman" class="svelte-18f0hit" data-svelte-h="svelte-1gxp8ci">LinkedIn</a></div></div> <p class="text-xs md:text-sm my-8"><i>Last updated: January 2025</i></p></section> <section class="svelte-18f0hit"><h2 id="publications_header" data-svelte-h="svelte-ai5cix">Selected Publications</h2> <ul id="main_pubs_list" class="svelte-5md2ap"><li class="svelte-5md2ap"><div class="pub_item svelte-5md2ap"><div class="my-auto w-full"><div class="pub_venue_name svelte-5md2ap">ACM CHI 2025 </div> <div><div class="pub_title svelte-5md2ap">SPECTRA: Personalizable Sound Recognition for Deaf and Hard of Hearing Users Through Interactive Machine Learning</div> <div class="pub_author_list svelte-5md2ap"><strong>Steven Goodman, </strong>Emma McDonnell, Jon E. Froehlich, Leah Findlater</div> <div class="pub_links_container svelte-5md2ap">(
              <span class="text-gray-700 italic">To appear</span>
              )</div> </div></div> <div class="pub_img_container svelte-5md2ap"><img class="pub_image svelte-5md2ap" src="images/2025_SPECTRA_square.png" alt="Part of Figure 5 in the paper, showing the user interface of an email composition tool and the 'Rewrite My Selection' feature described in this work. Copied here for decorative purposes."> </div></div> </li><li class="svelte-5md2ap"><div class="pub_item svelte-5md2ap"><div class="my-auto w-full"><div class="pub_venue_name svelte-5md2ap">Doctoral Dissertation, University of Washington | 2024 </div> <div><a href="papers/Goodman_UW2024_Dissertation.pdf"><div class="pub_title svelte-5md2ap">Human-Centered Sound Recognition Tools for Deaf and Hard of Hearing Users</div></a> <div class="pub_author_list svelte-5md2ap"><strong>Steven Goodman</strong></div> <div class="pub_links_container svelte-5md2ap">(
              <a href="papers/Goodman_UW2024_Dissertation.pdf" class="svelte-5md2ap">Paper</a> | <a href="https://www.proquest.com/openview/e985386300fcb204eb888156f04f6bfc/" class="svelte-5md2ap">ProQuest</a>
              )</div> </div></div> <div class="pub_img_container svelte-5md2ap"><img class="pub_image svelte-5md2ap" src="images/2024_Dissertation_overview.png" alt="Figure 1 in the dissertation, a graphic showing how three projects detailed in the dissertation each cover a different area of the traditional machine learning pipeline. Copied here for decorative purposes."> </div></div> </li><li class="svelte-5md2ap"><div class="pub_item svelte-5md2ap"><div class="my-auto w-full"><div class="pub_venue_name svelte-5md2ap">ACM CHI 2023 </div> <div><a href="papers/McDonnell_CHI2023_Easier-or-Harder.pdf"><div class="pub_title svelte-5md2ap">“Easier or Harder, Depending on Who the Hearing Person Is”: Codesigning Videoconferencing Tools for Small Groups with Mixed Hearing Status</div></a> <div class="pub_author_list svelte-5md2ap">Emma McDonnell, Soo Hyun Moon, Lucy Jiang, <strong>Steven Goodman, </strong>Raja Kushalnagar, Jon E. Froehlich, Leah Findlater</div> <div class="pub_links_container svelte-5md2ap">(
              <a href="papers/McDonnell_CHI2023_Easier-or-Harder.pdf" class="svelte-5md2ap">Paper</a> | <a href="https://youtu.be/pOpsIms3DTA" class="svelte-5md2ap">Talk</a> | <a href="https://doi.org/10.1145/3544548.3580809" class="svelte-5md2ap">doi</a>
              )</div> </div></div> <div class="pub_img_container svelte-5md2ap"> </div></div> </li><li class="svelte-5md2ap"><div class="pub_item svelte-5md2ap"><div class="my-auto w-full"><div class="pub_venue_name svelte-5md2ap">ACM ASSETS 2022 <span class="pub_award svelte-5md2ap"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32" fill="currentColor" preserveAspectRatio="xMidYMid meet" width="20" height="20" aria-hidden class="pr-1"><path d="M16,2l-4.55,9.22L1.28,12.69l7.36,7.18L6.9,30,16,25.22,25.1,30,23.36,19.87l7.36-7.17L20.55,11.22Z"></path></svg>Best Paper Nominee</span></div> <div><a href="papers/Goodman_ASSETS2022_LaMPost.pdf"><div class="pub_title svelte-5md2ap">LaMPost: Design and Evaluation of an AI-assisted Email Writing Prototype for Adults with Dyslexia</div></a> <div class="pub_author_list svelte-5md2ap"><strong>Steven Goodman, </strong>Andy Coenen, Aaron Donsbach, Tiffanie N. Horne, Michal Lahav, Robert MacDonald, Rain Breaw Michaels, Ajit Narayanan, Mahima Pushkarna, Rachel Sweeney, Meredith Ringel Morris</div> <div class="pub_links_container svelte-5md2ap">(
              <a href="papers/Goodman_ASSETS2022_LaMPost.pdf" class="svelte-5md2ap">Paper</a> | <a href="https://youtu.be/1JYUCcRcRg8" class="svelte-5md2ap">Talk</a> | <a href="https://doi.org/10.1145/3517428.3544819" class="svelte-5md2ap">doi</a>
              )</div> </div></div> <div class="pub_img_container svelte-5md2ap"><img class="pub_image svelte-5md2ap" src="images/2022_LaMPost_square.png" alt="Part of Figure 5 in the paper, showing the user interface of an email composition tool and the 'Rewrite My Selection' feature described in this work. Copied here for decorative purposes."> </div></div> </li><li class="svelte-5md2ap"><div class="pub_item svelte-5md2ap"><div class="my-auto w-full"><div class="pub_venue_name svelte-5md2ap">ACM CHI 2022 </div> <div><a href="papers/Jain_CHI2022_Protosound.pdf"><div class="pub_title svelte-5md2ap">ProtoSound: A Personalized and Scalable Sound Recognition System for Deaf and Hard of Hearing Users</div></a> <div class="pub_author_list svelte-5md2ap">Dhruv Jain, Khoa Nguyen, <strong>Steven Goodman, </strong>Rachel Grossman-Kahn, Hung Ngo, Aditya Kusupati, Ruofei Du, Alex Olwal, Leah Findlater, Jon Froehlich</div> <div class="pub_links_container svelte-5md2ap">(
              <a href="papers/Jain_CHI2022_Protosound.pdf" class="svelte-5md2ap">Paper</a> | <a href="https://www.youtube.com/watch?v=bDE95hKiLqw" class="svelte-5md2ap">Video</a> | <a href="https://github.com/makeabilitylab/ProtoSound" class="svelte-5md2ap">Code</a> | <a href="https://doi.org/10.1145/3491102.3502020" class="svelte-5md2ap">doi</a>
              )</div> </div></div> <div class="pub_img_container svelte-5md2ap"> </div></div> </li><li class="svelte-5md2ap"><div class="pub_item svelte-5md2ap"><div class="my-auto w-full"><div class="pub_venue_name svelte-5md2ap">ACM IMWUT 2021 </div> <div><a href="papers/Goodman_IMWUT2021_TowardUserDriven.pdf"><div class="pub_title svelte-5md2ap">Toward User-Driven Sound Recognizer Personalization with People Who Are d/Deaf or Hard of Hearing</div></a> <div class="pub_author_list svelte-5md2ap"><strong>Steven Goodman, </strong>Ping Liu, Dhruv Jain, Emma J. McDonnell, Jon Froehlich, Leah Findlater</div> <div class="pub_links_container svelte-5md2ap">(
              <a href="papers/Goodman_IMWUT2021_TowardUserDriven.pdf" class="svelte-5md2ap">Paper</a> | <a href="https://www.youtube.com/watch?v=GWNzKHhOvGE" class="svelte-5md2ap">Talk</a> | <a href="https://doi.org/10.1145/3463501" class="svelte-5md2ap">doi</a>
              )</div> </div></div> <div class="pub_img_container svelte-5md2ap"><img class="pub_image svelte-5md2ap" src="images/2021_TMSR_square.jpg" alt="Image from Figure 2 of the paper, showing a participant recording a kettle boiling sound on a smartphone recording app. Copied here for decorative purposes."> </div></div> </li><li class="svelte-5md2ap"><div class="pub_item svelte-5md2ap"><div class="my-auto w-full"><div class="pub_venue_name svelte-5md2ap">PACMHCI CSCW 2021 <span class="pub_award svelte-5md2ap"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32" fill="currentColor" preserveAspectRatio="xMidYMid meet" width="20" height="20" aria-hidden class="pr-1"><path d="M16,2l-4.55,9.22L1.28,12.69l7.36,7.18L6.9,30,16,25.22,25.1,30,23.36,19.87l7.36-7.17L20.55,11.22Z"></path></svg>Honorable Mention</span></div> <div><a href="papers/McDonnell_CSCWPACMHCI2021_SocialEnvironmentalTechnical.pdf"><div class="pub_title svelte-5md2ap">Social, Environmental, and Technical: Factors at Play in the Current Use and Future Design of Small-Group Captioning</div></a> <div class="pub_author_list svelte-5md2ap">Emma McDonnell, Ping Liu, <strong>Steven Goodman, </strong>Raja Kushalnagar, Jon Froehlich, Leah Findlater</div> <div class="pub_links_container svelte-5md2ap">(
              <a href="papers/McDonnell_CSCWPACMHCI2021_SocialEnvironmentalTechnical.pdf" class="svelte-5md2ap">Paper</a> | <a href="https://youtu.be/1TC8sfPQxxQ" class="svelte-5md2ap">Talk</a> | <a href="https://doi.org/10.1145/3479578" class="svelte-5md2ap">doi</a>
              )</div> </div></div> <div class="pub_img_container svelte-5md2ap"> </div></div> </li><li class="svelte-5md2ap"><div class="pub_item svelte-5md2ap"><div class="my-auto w-full"><div class="pub_venue_name svelte-5md2ap">ACM CHI 2020 </div> <div><a href="papers/Goodman_CHI2020_EvaluatingSmartwatchAcrossContexts.pdf"><div class="pub_title svelte-5md2ap">Evaluating Smartwatch-based Sound Feedback for Deaf and Hard-of-hearing Users Across Contexts</div></a> <div class="pub_author_list svelte-5md2ap"><strong>Steven Goodman, </strong>Susanne Kirchner, Rose Guttman, Dhruv Jain, Jon Froehlich, Leah Findlater</div> <div class="pub_links_container svelte-5md2ap">(
              <a href="papers/Goodman_CHI2020_EvaluatingSmartwatchAcrossContexts.pdf" class="svelte-5md2ap">Paper</a> | <a href="https://doi.org/10.1145/3313831.3376406" class="svelte-5md2ap">doi</a>
              )</div> </div></div> <div class="pub_img_container svelte-5md2ap"><img class="pub_image svelte-5md2ap" src="images/2020_Smartwatches_square.jpg" alt="A person sitting in a coffee shop looking at a smartwatch, which displays the direction of a sound occurring in their vicinity. Copied here for decorative purposes."> </div></div> </li><li class="svelte-5md2ap"><div class="pub_item svelte-5md2ap"><div class="my-auto w-full"><div class="pub_venue_name svelte-5md2ap">ACM ASSETS 2020 <span class="pub_award svelte-5md2ap"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32" fill="currentColor" preserveAspectRatio="xMidYMid meet" width="20" height="20" aria-hidden class="pr-1"><path d="M16,2l-4.55,9.22L1.28,12.69l7.36,7.18L6.9,30,16,25.22,25.1,30,23.36,19.87l7.36-7.17L20.55,11.22Z"></path></svg>Best Artifact Award</span></div> <div><a href="papers/Jain_ASSETS2020_Soundwatch.pdf"><div class="pub_title svelte-5md2ap">SoundWatch: Exploring Smartwatch-based Deep Learning Approaches to Support Sound Awareness for Deaf and Hard of Hearing Users</div></a> <div class="pub_author_list svelte-5md2ap">Dhruv Jain, Hung Ngo, Pratyush Patel, <strong>Steven Goodman, </strong>Leah Findlater, Jon Froehlich</div> <div class="pub_links_container svelte-5md2ap">(
              <a href="papers/Jain_ASSETS2020_Soundwatch.pdf" class="svelte-5md2ap">Paper</a> | <a href="https://doi.org/10.1145/3373625.3416991" class="svelte-5md2ap">doi</a>
              )</div> </div></div> <div class="pub_img_container svelte-5md2ap"> </div></div> </li><li class="svelte-5md2ap"><div class="pub_item svelte-5md2ap"><div class="my-auto w-full"><div class="pub_venue_name svelte-5md2ap">ACM ASSETS 2020 Poster </div> <div><a href="papers/Guo_POSTERASSETS2020_Holosound.pdf"><div class="pub_title svelte-5md2ap">HoloSound: Combining Speech and Sound Identification for Deaf or Hard of Hearing Users on a Head-mounted Display</div></a> <div class="pub_author_list svelte-5md2ap">Ru Guo, Robin Yiru Yang, Johnson Kuang, Xue Bin, Dhruv Jain, <strong>Steven Goodman, </strong>Leah Findlater, Jon Froehlich</div> <div class="pub_links_container svelte-5md2ap">(
              <a href="papers/Guo_POSTERASSETS2020_Holosound.pdf" class="svelte-5md2ap">Paper</a> | <a href="https://www.youtube.com/watch?v=-F9yL-XM02o" class="svelte-5md2ap">Video</a> | <a href="https://doi.org/10.1145/3373625.3418031" class="svelte-5md2ap">doi</a>
              )</div> </div></div> <div class="pub_img_container svelte-5md2ap"> </div></div> </li><li class="svelte-5md2ap"><div class="pub_item svelte-5md2ap"><div class="my-auto w-full"><div class="pub_venue_name svelte-5md2ap">ACM ISWC 2020 </div> <div><a href="papers/Jain_ISWC2020_FieldStudyOfATactile.pdf"><div class="pub_title svelte-5md2ap">Field Study of a Tactile Sound Awareness Device for Deaf Users</div></a> <div class="pub_author_list svelte-5md2ap">Dhruv Jain, Brendon Chiu, <strong>Steven Goodman, </strong>Chris Schmandt, Leah Findlater, Jon Froehlich</div> <div class="pub_links_container svelte-5md2ap">(
              <a href="papers/Jain_ISWC2020_FieldStudyOfATactile.pdf" class="svelte-5md2ap">Paper</a> | <a href="https://doi.org/10.1145/3410531.3414291" class="svelte-5md2ap">doi</a>
              )</div> </div></div> <div class="pub_img_container svelte-5md2ap"> </div></div> </li><li class="svelte-5md2ap"><div class="pub_item svelte-5md2ap"><div class="my-auto w-full"><div class="pub_venue_name svelte-5md2ap">ACM CHI 2020 </div> <div><a href="papers/Jain_CHI2020_Homesound.pdf"><div class="pub_title svelte-5md2ap">HomeSound: An Iterative Field Deployment of an In-Home Sound Awareness System for Deaf or Hard of Hearing Users</div></a> <div class="pub_author_list svelte-5md2ap">Dhruv Jain, Kelly Mack, Akli Amrous, <strong>Steven Goodman, </strong>Matt Wright, Leah Findlater, Jon Froehlich</div> <div class="pub_links_container svelte-5md2ap">(
              <a href="papers/Jain_CHI2020_Homesound.pdf" class="svelte-5md2ap">Paper</a> | <a href="https://doi.org/10.1145/3313831.3376758" class="svelte-5md2ap">doi</a>
              )</div> </div></div> <div class="pub_img_container svelte-5md2ap"> </div></div> </li><li class="svelte-5md2ap"><div class="pub_item svelte-5md2ap"><div class="my-auto w-full"><div class="pub_venue_name svelte-5md2ap">ACM CHI 2019 Extended Abstracts </div> <div><a href="papers/Goodman_CHI2019EA_SocialHMD.pdf"><div class="pub_title svelte-5md2ap">Social Tensions with Head-Mounted Displays for Accessibility</div></a> <div class="pub_author_list svelte-5md2ap"><strong>Steven Goodman, </strong>Dhruv Jain, Jon Froehlich, Brock Craft, Leah Findlater</div> <div class="pub_links_container svelte-5md2ap">(
              <a href="papers/Goodman_CHI2019EA_SocialHMD.pdf" class="svelte-5md2ap">Paper</a>
              )</div> </div></div> <div class="pub_img_container svelte-5md2ap"> </div></div> </li> </ul></section> <section class="svelte-18f0hit"><h2 id="talks_header" data-svelte-h="svelte-dq7294">Talks &amp; Videos</h2> <ul id="talks_list" class="svelte-jcq3mh"><li class="svelte-jcq3mh"><div class="talk_date svelte-jcq3mh">April 18, 2023</div> <div><a href="slides/UW-2023_Dissertation-Proposal_slides.pdf"><img src="images/UW2023_Proposal_slide-preview.png" alt="First slide of the talk with white text on a blue background. The title reads: Human-Centered Sound Recognition Tools for Deaf and Hard of Hearing People."> </a></div> <h4 class="svelte-jcq3mh">Human-Centered Sound Recognition Tools</h4> <div class="talk_note svelte-jcq3mh">Public proposal at the University of Washington  | <a href="slides/UW-2023_Dissertation-Proposal_slides.pdf">Slides</a></div> </li><li class="svelte-jcq3mh"><div class="talk_date svelte-jcq3mh">October 25, 2022</div> <div><div class="aspect-w-16 aspect-h-9"><iframe title="Youtube video for LaMPost: AI-assisted Writing for Dyslexia" src="https://www.youtube.com/embed/1JYUCcRcRg8?rel=0&amp;cc_load_policy=1&amp;iv_load_policy=3&amp;color=white" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> </div></div> <h4 class="svelte-jcq3mh">LaMPost: AI-assisted Writing for Dyslexia</h4> <div class="talk_note svelte-jcq3mh">ASSETS 2022 in Athens, Greece  | <a href="slides/ASSETS-2022_LaMPost_slides.pdf">Slides</a></div> </li><li class="svelte-jcq3mh"><div class="talk_date svelte-jcq3mh">September 22, 2021</div> <div><div class="aspect-w-16 aspect-h-9"><iframe title="Youtube video for Toward User-Driven Sound Recognizer Personalization" src="https://www.youtube.com/embed/v5qvlZD6aKE?rel=0&amp;cc_load_policy=1&amp;iv_load_policy=3&amp;color=white" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> </div></div> <h4 class="svelte-jcq3mh">Toward User-Driven Sound Recognizer Personalization</h4> <div class="talk_note svelte-jcq3mh">Virtual event for paper at UbiComp 2021  | <a href="slides/IMWUT-2021_TMSR_slides.pdf">Slides</a></div> </li><li class="svelte-jcq3mh"><div class="talk_date svelte-jcq3mh">November 22, 2019</div> <div><a href="slides/CHI-2020_Smartwatches_slides.pdf"><img src="images/CHI2020_Smartwatches_slide-preview.png" alt="First slide of the talk with an image of an individual standing at a crosswalk and looking at a smartwatch on their wrist. In the background, a car drives past while a bicyclist approaches. The title reads: Evaluating Smartwatch-based Sound Feedback for Deaf and Hard-of-Hearing Users Across Contexts."> </a></div> <h4 class="svelte-jcq3mh">Smartwatch Sound Feedback Across Contexts</h4> <div class="talk_note svelte-jcq3mh">University of Washington (in anticipation of CHI 2020 paper)  | <a href="slides/CHI-2020_Smartwatches_slides.pdf">Slides</a></div> </li><li class="svelte-jcq3mh"><div class="talk_date svelte-jcq3mh">May 5, 2019</div> <div><a href="slides/CHI-SHMD-2019_SocialHMD_slides.pdf"><img src="images/CHI2019EA_SocialHMD_slide-preview.png" alt="First slide of the talk with an image of a two individuals talking. One is wearing a head-mounted display that is projecting simulated captions beneath the other person. The title reads: Social Tensions with HMDs for Accessibility."> </a></div> <h4 class="svelte-jcq3mh">Social Tensions with HMDs for Accessibility</h4> <div class="talk_note svelte-jcq3mh">Social HMDs workshop at CHI 2019 in Glasgow, Scotland  | <a href="slides/CHI-SHMD-2019_SocialHMD_slides.pdf">Slides</a></div> </li></ul> <h3 data-svelte-h="svelte-151j2ls">Videos</h3> <ul id="videos_list" class="svelte-jcq3mh"><li class="svelte-jcq3mh"><div class="aspect-w-16 aspect-h-9"><iframe title="Youtube video for ProtoSound: Personalized, Scalable Sound Awareness" src="https://www.youtube.com/embed/bDE95hKiLqw?rel=0&amp;cc_load_policy=1&amp;iv_load_policy=3&amp;color=white" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div> <h4 class="svelte-jcq3mh">ProtoSound: Personalized, Scalable Sound Awareness</h4> <div>April 3, 2022</div> <div class="video_note svelte-jcq3mh">Produced video in support of co-authored work at CHI 2022.</div> </li><li class="svelte-jcq3mh"><div class="aspect-w-16 aspect-h-9"><iframe title="Youtube video for HoloSound: AR Sound Awareness" src="https://www.youtube.com/embed/-F9yL-XM02o?rel=0&amp;cc_load_policy=1&amp;iv_load_policy=3&amp;color=white" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div> <h4 class="svelte-jcq3mh">HoloSound: AR Sound Awareness</h4> <div>July 31, 2020</div> <div class="video_note svelte-jcq3mh">Produced video in support a co-authored poster at ASSETS 2020.</div> </li> </ul></section></main> <footer data-svelte-h="svelte-dfhj06"><div class="foot_div"></div></footer> </div> 
			
			<script>
				{
					__sveltekit_nwrfz0 = {
						base: new URL(".", location).pathname.slice(0, -1),
						env: {}
					};

					const element = document.currentScript.parentElement;

					const data = [null,null];

					Promise.all([
						import("./app/immutable/entry/start.8c1e7e81.js"),
						import("./app/immutable/entry/app.e51145c7.js")
					]).then(([kit, app]) => {
						kit.start(app, element, {
							node_ids: [0, 2],
							data,
							form: null,
							error: null
						});
					});
				}
			</script>
		</div>
  </body>
</html>
